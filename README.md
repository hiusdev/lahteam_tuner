# ğŸ¨ LahTeam Tuner

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Helper library cho viá»‡c train LoRA trÃªn Google Colab** - Há»— trá»£ FLUX.2, Qwen Image, vÃ  Z-Image Turbo.

## âœ¨ TÃ­nh nÄƒng

- ğŸš€ **Tá»± Ä‘á»™ng táº£i model** - Chá»‰ 1 lá»‡nh Ä‘á»ƒ táº£i VAE, Text Encoder, DiT
- âš™ï¸ **Auto config** - Tá»± Ä‘á»™ng detect model type vÃ  táº¡o cáº¥u hÃ¬nh phÃ¹ há»£p
- ğŸ“Š **Dataset config** - Táº¡o TOML config cho dataset training
- ğŸ”§ **Training helpers** - Build command line arguments tá»± Ä‘á»™ng
- ğŸ“ **Logger patch** - Thay tháº¿ logger thÃ nh print() cho Colab

## ğŸ“¦ Models Ä‘Æ°á»£c há»— trá»£

| Model | Type | Description |
|-------|------|-------------|
| `z_image_turbo` | Z-Image | MÃ´ hÃ¬nh Z-Image Turbo |
| `qwen_image` | Qwen | Qwen Image generation |
| `qwen_image_edit` | Qwen | Qwen Image editing |
| `qwen_image_edit_2509` | Qwen | Qwen Image editing v2509 |
| `flux2_dev` | FLUX.2 | FLUX.2 Dev (Mistral 3) |
| `flux2_klein_4b` | FLUX.2 | FLUX.2 Klein 4B |
| `flux2_klein_base_4b` | FLUX.2 | FLUX.2 Klein Base 4B â­ |
| `flux2_klein_9b` | FLUX.2 | FLUX.2 Klein 9B |
| `flux2_klein_base_9b` | FLUX.2 | FLUX.2 Klein Base 9B â­ |

> â­ **Recommended**: Sá»­ dá»¥ng `klein_base_*` cho training LoRA

## ğŸš€ CÃ i Ä‘áº·t

```python
!git clone https://github.com/hiusdev/lahteam_tuner
!pip install -q -e lahteam_tuner
```

## ğŸ“š API Reference

### Download Functions

```python
from lahteam_tuner import download_model, download_flux2_model, download_qwen_model

# Auto-detect model type
paths = download_model("flux2_klein_base_4b", "/content/models", hf_token="...")
# Returns: {"vae_path": ..., "text_encoders_path": ..., "dit_path": ...}

# Hoáº·c gá»i trá»±c tiáº¿p
paths = download_flux2_model("flux2_klein_base_4b", "/content/models")
paths = download_qwen_model("z_image_turbo", "/content/models")
```

### Dataset Config

```python
from lahteam_tuner import create_dataset_config

path = create_dataset_config(
    data_dir="/path/to/images",
    control_dir="/path/to/control",  # Optional
    config_dir="/path/to/config",
    resolution=(1024, 1024),
    batch_size=2,
    default_repeats=10,
    caption_extension=".txt",
    enable_bucket=True,
    model_type="flux2_klein_base_4b"
)
```

### Model Config

```python
from lahteam_tuner import get_model_config, MODEL_CONFIG, FLUX2_CONFIG

config = get_model_config("flux2_klein_base_4b")
# Returns:
# {
#     "vae": {...},
#     "text_encoder": {...},
#     "dit": {...},
#     "network_module": "networks.lora_flux_2",
#     "script_prefix": "flux_2",
#     "model_version": "klein-base-4b",
#     "training_params": {
#         "timestep_sampling": "shift",
#         "fp8_base": True,
#         ...
#     }
# }
```

### Utility Functions

```python
from lahteam_tuner import (
    # Model info
    is_flux2_model,          # Kiá»ƒm tra cÃ³ pháº£i FLUX.2 khÃ´ng
    is_edit_model,           # Kiá»ƒm tra cÃ³ pháº£i Edit model khÃ´ng
    get_flux2_version,       # Láº¥y version string (dev, klein-4b, ...)
    get_script_prefix,       # Láº¥y prefix cho script (flux_2, qwen_image, ...)
    get_network_module,      # Láº¥y network module path
    
    # Training
    build_train_args,        # Build command line arguments tá»« dict
    generate_sample_prompts, # Táº¡o file sample prompts
    
    # Logger patch
    patch_logger_files,      # Patch logger thÃ nh print() cho Colab
    
    # File utils
    ensure_dir,              # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
    find_images_in_folder,   # TÃ¬m áº£nh trong folder
    count_images_in_folder,  # Äáº¿m sá»‘ áº£nh trong folder
    read_caption,            # Äá»c file caption
    write_caption,           # Ghi file caption
    
    # Dataset
    download_and_unzip,      # Táº£i vÃ  giáº£i nÃ©n dataset tá»« URL
    get_repeats_from_folder_name,  # Láº¥y repeats tá»« tÃªn folder (10_name)
)
```

## ğŸ“ Cáº¥u trÃºc thÆ° viá»‡n

```
lahteam_tuner/
â”œâ”€â”€ __init__.py      # Public API exports
â”œâ”€â”€ config.py        # Model configurations (QWEN, FLUX.2)
â”œâ”€â”€ download.py      # Model download functions
â”œâ”€â”€ utils.py         # Helper utilities
â”œâ”€â”€ setup.py         # Package setup
â”œâ”€â”€ LICENSE          # MIT License
â””â”€â”€ README.md
```

## ğŸ“ License

MIT License - Xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ‘¥ Authors

- **LahTeam.VN** - [Website](https://lahteam.vn)

## ğŸ™ Credits

- [kohya-ss/musubi-tuner](https://github.com/kohya-ss/musubi-tuner) - Base training framework
- [Comfy-Org](https://huggingface.co/Comfy-Org) - FLUX.2 model hosting
- [Qwen](https://huggingface.co/Qwen) - Qwen Image models

---

<p align="center">
  <sub>ğŸ¤– This project was developed with AI assistance (Claude/Gemini)</sub>
</p>
